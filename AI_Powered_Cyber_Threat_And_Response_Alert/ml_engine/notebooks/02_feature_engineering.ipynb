{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8def9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda17d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "INPUT_FILE = \"../data/processed/cleaned_data.parquet\"\n",
    "MODEL_PATH = \"../models\" # Make sure this matches your folder name (ml_engine/models)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf441706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Data...\")\n",
    "df = pd.read_parquet(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a4b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Features (X) and Target (y)\n",
    "X = df.drop(columns=['Label', 'attack_cat'])\n",
    "y = df['Label'] # Binary Target: 0=Normal, 1=Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462a996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Column Types\n",
    "# Categorical = Text (proto, service, state)\n",
    "# Numeric = Everything else\n",
    "cat_cols = ['proto', 'service', 'state']\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610e6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BUILD THE PREPROCESSING PIPELINE ---\n",
    "# This is the \"Industry Standard\" way.\n",
    "# We create a transformer that handles numbers and text separately.\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), num_cols),\n",
    "        # handle_unknown='ignore' PREVENTS CRASHES on new/weird protocols\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f6bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting Data...\n"
     ]
    }
   ],
   "source": [
    "# --- SPLIT DATA ---\n",
    "print(\"Splitting Data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca3a1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Preprocessor...\n"
     ]
    }
   ],
   "source": [
    "# --- FIT & TRANSFORM ---\n",
    "print(\"Fitting Preprocessor...\")\n",
    "# We fit only on TRAIN data to avoid data leakage\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ed1c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/preprocessor.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- SAVE EVERYTHING ---\n",
    "# We save the preprocessor itself. The API will load this to process new alerts.\n",
    "joblib.dump(preprocessor, f\"{MODEL_PATH}/preprocessor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a336d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete. Preprocessor saved.\n"
     ]
    }
   ],
   "source": [
    "# Save processed arrays for the next notebook (Training)\n",
    "joblib.dump((X_train_processed, y_train), f\"{MODEL_PATH}/train_data.joblib\")\n",
    "joblib.dump((X_test_processed, y_test), f\"{MODEL_PATH}/test_data.joblib\")\n",
    "\n",
    "print(\"Feature Engineering Complete. Preprocessor saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
